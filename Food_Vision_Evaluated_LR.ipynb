{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lWP5aDxI9EK"
   },
   "source": [
    "# Food Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ol6L6tVIhIl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtW-vrgZaSI-",
    "outputId": "e0832836-093f-4625-bc27-4d4587434464"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbx0VuyLvR_i"
   },
   "source": [
    "## Load the Dataset from Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKs1fyhLfXCj"
   },
   "outputs": [],
   "source": [
    "(train_data, test_data), ds_info = tfds.load(\n",
    "    name=\"food101\",\n",
    "    split=[\"train\", \"validation\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BplsNXC7B522",
    "outputId": "870fe96d-0c75-4664-e913-1b489d524d1a"
   },
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6g1UBjZvDKn",
    "outputId": "33c773b7-72aa-4248-aac1-9c7817b2f2a8"
   },
   "outputs": [],
   "source": [
    "print(f\"Dataset info: {ds_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIMMUNXv8KAG"
   },
   "outputs": [],
   "source": [
    "class_names = ds_info.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnMfFKzO6HNd"
   },
   "outputs": [],
   "source": [
    "sample = train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "x9nAyF987Aaa",
    "outputId": "6fd79088-d487-451e-d312-a5724646bf63"
   },
   "outputs": [],
   "source": [
    "for a,b in sample:\n",
    "  print(f'Data Type of tensor {a.dtype}')\n",
    "  print(f'Data Shape of tensor {a.shape}')\n",
    "  print(f'Label {b} which means {class_names[b]}')\n",
    "  plt.figure(figsize=(6,6))\n",
    "  plt.title(f'{class_names[b]}')\n",
    "  plt.imshow(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrnkaQbhPdsz"
   },
   "source": [
    "## Pre-Process the Data\n",
    "\n",
    "Currently we have tensors of **uint8** datatype. I plan on running mixed precision training, therefore we'd need **float16/32** bit tensors. They're also of various shapes, and non - normalised, which models tend to prefer. Let's fix this, while also implementing batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "qFsUPGFTP-80",
    "outputId": "bb1e61ea-c145-46ec-a3be-c5ba7e621abf"
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image,label, new_shape=[224,224]):\n",
    "  image = tf.image.resize(image, new_shape)\n",
    "  new_image = tf.cast(image, tf.float32)\n",
    "  new_image = new_image/255.0\n",
    "  return new_image, label\n",
    "a,b = pre_process_image(a,b)\n",
    "print(a.dtype)\n",
    "print(a.shape)\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1YZVJfb9WAy"
   },
   "outputs": [],
   "source": [
    "# Batching the data, and then running shuffle again\n",
    "train_data = train_data.map(map_func=pre_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# shuffle and prefetch, prefetching is getting the next segment of data to shuffle while you shuffle the current one\n",
    "# the prefetching is on CPU, while map is on the GPU. the AUTOTUNE parrallel call enables parallelization\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_data = test_data.map(map_func=pre_process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_data = test_data.shuffle(buffer_size=1000).batch(batch_size=32, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJEMcRbLB1Ss"
   },
   "source": [
    "## Creating some callbacks, in case we need to investigate further down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f--HyFDU-mai"
   },
   "outputs": [],
   "source": [
    "# Creating a Tensorboard Callback, just to log metrics during training such that we can look later on Tensorboard at them\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZDRVgCOB_YS"
   },
   "outputs": [],
   "source": [
    "# Model Checkpoint to save weights during training\n",
    "checkpoint_path = 'checkpoint_path/cp.weights.h5'\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,monitor='val_acc',\n",
    "                                                      verbose=0,save_best_only=True,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l86lsGMXSVSZ"
   },
   "source": [
    "## Using Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMoJc-WOSfko",
    "outputId": "d415e98b-9754-4493-bb06-bc6934ad072f"
   },
   "outputs": [],
   "source": [
    "# Using mixed precision training speeds up model training massively. By default, most tensor parameters are stored\n",
    "# as 32 bit. By setting some such as activations, and CNN window weights as 16bit we can massively improve\n",
    "# efficiency (hlaving our space). We still keep weights and biases as 32bit though\n",
    "!nvidia-smi -L\n",
    "# We're using Tesla T4 GPU. This has a compute capability of 7.5, we need 7 so we're all good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rQxHMS9TPlm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16') # making sure we've mixed 16 and 32 bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8UrKz4KXn4T"
   },
   "source": [
    "## Build the Feature Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybW_LpwLtQ5P"
   },
   "outputs": [],
   "source": [
    "#data augmentation - the benefit of incorporating it into the model is that it'll run on the gpu which is quicker\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_aug = tf.keras.Sequential([layers.RandomFlip('vertical'),\n",
    "                                layers.RandomHeight(0.2),\n",
    "                                layers.RandomWidth(0.2),\n",
    "                                layers.RandomRotation(0.2),\n",
    "                                layers.RandomZoom(0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS0tNvtcXslp"
   },
   "outputs": [],
   "source": [
    "# We're gonna use EficcientNet B0 for this one\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "# Define input shape\n",
    "input = layers.Input(shape=(224,224,3), name='input_layer')\n",
    "input = data_aug(input)\n",
    "\n",
    "#Instntiate Base Model\n",
    "base = tf.keras.applications.EfficientNetB0(include_top=False)(input)\n",
    "base.trainable= False\n",
    "\n",
    "# Global Pooling 2D for a Feature Vector\n",
    "pooling = layers.GlobalAveragePooling2D(name='pooling_layer')(base)\n",
    "\n",
    "# Output\n",
    "output = layers.Dense(len(class_names), activation='softmax', dtype = 'float32', name = 'output')(pooling)\n",
    "\n",
    "# create the model and compile\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPG7TPsecZ6B",
    "outputId": "0184ff6e-aaf8-4325-f986-36e23fb5f9e7"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: # just double checking\n",
    "  print(f'Layer Name {layer.name}', end = ', ')\n",
    "  print(f'Layer Type {layer.dtype}', end = ', ')\n",
    "  print(f'Layer Policy {layer.dtype_policy}')\n",
    "  print('---')\n",
    "for layer in model.layers[1].layers:\n",
    "  print(f'Layer Name {layer.name}', end = ', ')\n",
    "  print(f'Layer Type {layer.dtype}', end = ', ')\n",
    "  print(f'Layer Policy {layer.dtype_policy}')\n",
    "  print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjXT6yAyYoDE",
    "outputId": "397b4959-6875-47f5-abf8-4bc8a988fcf2"
   },
   "outputs": [],
   "source": [
    "food_vision_history = model.fit(train_data, batch_size=32, epochs=5,\n",
    "          callbacks=[model_checkpoint, create_tensorboard_callback('Food_Vision', 'Iteration_1')],\n",
    "          steps_per_epoch=len(train_data), validation_data=test_data, validation_steps=int(len(test_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-Y77gneYiEc"
   },
   "source": [
    "## Evaluate Model on all Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_XSSotiYmP5"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data) # Let's see how the model does on the entireity of the test data\n",
    "# Also, lets save it before we fine tune it\n",
    "model.save('Food_Vision_model_non_fine_tuned.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms_XCIetZTsI"
   },
   "source": [
    "## Fine Tuning by unfreezing EfficientNet Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myIm95jfZZti"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[1].layers:\n",
    "  layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAesp6e8giDH"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "  print(f'layer trainabale  = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyfqEc1jguC6"
   },
   "outputs": [],
   "source": [
    "fine_tuned_food_vision_history = model.fit(train_data, batch_size=32, epochs=10, initial_epoch=5,\n",
    "          callbacks=[model_checkpoint, create_tensorboard_callback('Food_Vision', 'Iteration_2')],\n",
    "          steps_per_epoch=len(train_data), validation_data=test_data, validation_steps=int(0.15*len(test_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgEDxSNjmFpg"
   },
   "source": [
    "## Evaluate fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfR3QFwLmKBU"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)\n",
    "model.save('fine_tuned_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYyhZiCEjVT5"
   },
   "source": [
    "## Plot Model Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combining training histories and visualize \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_1 = pd.DataFrame(food_vision_history.history)\n",
    "df_2 = pd.DataFrame(fine_tuned_food_vision_history.history)\n",
    "total_history = pd.concat([df_1, df_2], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Plot accuracy and loss curves\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(total_history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(total_history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(total_history['loss'], label='Train Loss')\n",
    "plt.plot(total_history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test dataset \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Get test data predictions\n",
    "y_true = np.concatenate([y for x, y in test_data], axis=0)\n",
    "y_pred_probs = model.predict(test_data, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_labels = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_true_labels, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90880f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize sample predictions\n",
    "import random\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img_batch, label_batch = test_data.next()\n",
    "    img = img_batch[0]\n",
    "    true_label = np.argmax(label_batch[0])\n",
    "    pred_prob = model.predict(img_batch)[0]\n",
    "    pred_label = np.argmax(pred_prob)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    color = \"green\" if pred_label == true_label else \"red\"\n",
    "    plt.title(f\"T: {class_names[true_label]}\\nP: {class_names[pred_label]}\", color=color)\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
